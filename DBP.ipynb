{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.datasets import DBpedia\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.data.utils import ngrams_iterator\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchtext.data.functional import to_map_style_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size:  650665\n"
     ]
    }
   ],
   "source": [
    "tokenizer = get_tokenizer('basic_english')\n",
    "train_iter = DBpedia(split='train')\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for _, text in data_iter:\n",
    "        tokens = tokenizer(text)\n",
    "        yield list(ngrams_iterator(tokens, 2))\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_iter), min_freq=5, specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "text_pipeline = lambda x: vocab(list(ngrams_iterator(tokenizer(x), 2)))\n",
    "label_pipeline = lambda x: int(x) - 1\n",
    "print('vocab_size: ', len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "    for (_label, _text) in batch:\n",
    "        label_list.append(label_pipeline(_label))  # '1', '2', '3', '4' -> [0, 1, 2, 3]\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)  # [475, 21, 30, 5297]\n",
    "        text_list.append(processed_text)\n",
    "        offsets.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)  # input의 누적 합계를 반환\n",
    "    text_list = torch.cat(text_list)  # batch 내의 모든 단어가 일렬로 들어감 -> nn.Embedding 에 들어가기 위해 하나로 합쳐짐\n",
    "\n",
    "    return label_list, text_list, offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class FastText(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, num_class, dropout_p):\n",
    "        super(FastText, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embedding_size, sparse=True)\n",
    "        nn.init.normal_(self.embedding.weight, mean=0.0, std=0.5)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.linear = nn.Linear(embedding_size, num_class, bias=True)\n",
    "        nn.init.normal_(self.linear.weight, mean=0.0, std=0.5)\n",
    "        self.linear.bias.data.zero_()\n",
    "\n",
    "        \n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        embedded = self.dropout(embedded)\n",
    "        return self.linear(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "log_interval = 3000\n",
    "\n",
    "def train(model, dataloader, criterion, optimizer, scheduler, clip):\n",
    "    model.train()\n",
    "    acc, count = 0, 0\n",
    "    s_time = time.time()\n",
    "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        predicted_label = model(text, offsets)  # |predicted_label| = (batch, num_classes)\n",
    "        loss = criterion(predicted_label, label)\n",
    "\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(model.parameters(), clip, norm_type=2)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        acc += (predicted_label.argmax(1) == label).sum().item()  # 같으면 1 -> 쭉 더함 \n",
    "        count += label.size(0)  # batch 때문에 size(0)으로 카운트 셈\n",
    "\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elasped = (time.time() - s_time)\n",
    "            print('accuracy: {}, time: {}[s]'.format(acc/count, int(elasped)))\n",
    "            s_time = time.time()   \n",
    "    return acc/count\n",
    "\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    v_total_acc, v_total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (v_label, v_text, v_offsets) in dataloader:\n",
    "            v_predicted_label = model(v_text, v_offsets)\n",
    "            v_total_acc += (v_predicted_label.argmax(1) == v_label).sum().item()\n",
    "            v_total_count += v_label.size(0)\n",
    "\n",
    "    return v_total_acc/v_total_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "from torchtext.data.functional import to_map_style_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_class:  14\n"
     ]
    }
   ],
   "source": [
    "train_iter = DBpedia(split='train')\n",
    "num_class = len(set([label for (label, text) in train_iter]))\n",
    "print('num_class: ', num_class)\n",
    "\n",
    "save_dir = './saved_model/dbpedia'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "save_path = os.path.join(save_dir, 'ckpt.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_size = 64\n",
    "dropout_p = 0.2\n",
    "model = FastText(vocab_size, embedding_size, num_class, dropout_p)\n",
    "max_epoch = 5\n",
    "lr = 0.2\n",
    "lr_decay = 0.99\n",
    "step_size = 1000\n",
    "batch_size = 64\n",
    "clip = 3\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adagrad(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size, gamma=lr_decay)\n",
    "\n",
    "train_iter, test_iter = DBpedia()\n",
    "train_dataset = to_map_style_dataset(train_iter)\n",
    "test_dataset = to_map_style_dataset(test_iter)\n",
    "num_train = int(len(train_dataset) * 0.95)\n",
    "split_train_, split_valid_ = random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n",
    "\n",
    "train_dataloader = DataLoader(split_train_, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "valid_dataloader = DataLoader(split_valid_, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------epoch: 1/5\n",
      "accuracy: 0.9776532822392536, time: 76[s]\n",
      "accuracy: 0.9818441718046992, time: 77[s]\n",
      "-----------------------------------------------------------\n",
      "epoch   1 | time: 215.20s | valid accuracy:    0.987 \n",
      "-----------------------------------------------------------\n",
      "----------epoch: 2/5\n",
      "accuracy: 0.9974383538820393, time: 74[s]\n",
      "accuracy: 0.9974170971504749, time: 73[s]\n",
      "----------epoch: 3/5\n",
      "accuracy: 0.9991981839386871, time: 73[s]\n",
      "accuracy: 0.9992423137810365, time: 72[s]\n",
      "----------epoch: 4/5\n",
      "accuracy: 0.9997552899033656, time: 69[s]\n",
      "accuracy: 0.9997604565905682, time: 68[s]\n",
      "----------epoch: 5/5\n",
      "accuracy: 0.9998854548483839, time: 77[s]\n",
      "accuracy: 0.9998932469588402, time: 70[s]\n"
     ]
    }
   ],
   "source": [
    "def run_train():\n",
    "  best_accu = 0\n",
    "\n",
    "  for epoch in range(0, max_epoch):\n",
    "    print('-' * 10 + 'epoch: {}/{}'.format(epoch+1, max_epoch))\n",
    "    epoch_start_time = time.time()\n",
    "    total_acc = train(model, train_dataloader, criterion, optimizer, scheduler, clip)\n",
    "    accu_val = evaluate(model, valid_dataloader)\n",
    "    if best_accu < accu_val:\n",
    "      best_accu = accu_val\n",
    "      torch.save({'epoch': epoch + 1, 'model_state_dict': model.state_dict()}, save_path)\n",
    "      print('-' * 59)\n",
    "      print('epoch {:3d} | time: {:5.2f}s | valid accuracy: {:8.3f} '.format(epoch+1, time.time() - epoch_start_time, accu_val))\n",
    "      print('-' * 59)\n",
    "\n",
    "run_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9872285714285715\n"
     ]
    }
   ],
   "source": [
    "accuracy = evaluate(model, test_dataloader)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1\n",
      "Accuracy:  0.9878285714285714\n"
     ]
    }
   ],
   "source": [
    "save_dir = './saved_model/dbpedia'\n",
    "load_path = save_dir + '/ckpt.pth'\n",
    "checkpoint = torch.load(load_path)\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "print('epoch: ', epoch)\n",
    "accuracy = evaluate(model, test_dataloader)\n",
    "\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ef7f9a8012d9131766e31894c279374cc63c73121ed4db3b9e67a294a4bf0e74"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
